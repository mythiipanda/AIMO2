{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-29 12:55:01 config.py:1668] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 10-29 12:55:05 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 10-29 12:55:05 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='Qwen/Qwen2.5-Math-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-Math-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-Math-7B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 10-29 12:55:05 utils.py:772] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 10-29 12:55:05 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 10-29 12:55:05 selector.py:115] Using XFormers backend.\n",
      "INFO 10-29 12:55:06 model_runner.py:1056] Starting to load model Qwen/Qwen2.5-Math-7B-Instruct...\n",
      "INFO 10-29 12:55:07 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 10-29 12:55:07 selector.py:115] Using XFormers backend.\n",
      "INFO 10-29 12:55:07 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6635ba46c4aa4327aa038da8c1c28e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:  68%|######8   | 2.64G/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e8c8c4da26408597961a8b61649fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  78%|#######8  | 3.08G/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccf46bb69224dd4b4e94af5889635d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:  70%|#######   | 2.71G/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c169ffa92d0d469ea61d0c4a8252a3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:  98%|#########8| 3.49G/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7937e4a3b36e494289c139e8aeda1874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a88bc8b39d44dcba7f04b872894cf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-29 12:57:26 model_runner.py:1067] Loading model weights took 14.2418 GB\n",
      "INFO 10-29 12:59:07 gpu_executor.py:122] # GPU blocks: 753, # CPU blocks: 4681\n",
      "INFO 10-29 12:59:07 gpu_executor.py:126] Maximum concurrency for 4096 tokens per request: 2.94x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import torch\n",
    "import vllm\n",
    "\n",
    "# Initialize LLM and Tokenizer\n",
    "llm = vllm.LLM(\n",
    "    \"Qwen/Qwen2.5-Math-7B-Instruct\",  # Ensure this model is supported\n",
    "    tensor_parallel_size=1,  # or 4 based on available resources\n",
    "    gpu_memory_utilization=0.95, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\", \n",
    "    enforce_eager=True,\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving problem 057f8a:\n",
      "Three airline companies operate flights from Dodola island. Each company has a different schedule of departures. The first company departs every 100 days, the second every 120 days and the third every 150 days. What is the greatest positive integer $d$ for which it is true that there will be $d$ consecutive days without a flight from Dodola island, regardless of the departure times of the various airlines?\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "from IPython import get_ipython\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def solve_problem(id, problem):\n",
    "    # Prompt engineering\n",
    "    sampling_params = vllm.SamplingParams(\n",
    "      temperature=0.00,\n",
    "      max_tokens=1024\n",
    "    )\n",
    "    prompt = f\"Let's solve the following AIMO2 problem step by step:\\n{problem}\\n\\nStep 1: \"\n",
    "\n",
    "    # Generate solution using LLM\n",
    "    solution_steps = llm.generate(prompt, sampling_params=sampling_params, use_tqdm=False)\n",
    "\n",
    "    # Extract Python code from solution steps\n",
    "    python_code = extract_python_code(solution_steps)\n",
    "\n",
    "    # Run Python code using PythonREPL\n",
    "    result = PythonREPL.run(python_code)\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_python_code(solution_steps):\n",
    "    # Extract Python code from the generated solution steps\n",
    "    # Implement this function based on the format of the generated solution\n",
    "    # Return the extracted Python code\n",
    "    \n",
    "    # Assuming the Python code is enclosed in ```python and ``` delimiters\n",
    "    python_code = re.search(r\"```python(.*?)```\", solution_steps, re.DOTALL)\n",
    "    \n",
    "    if python_code:\n",
    "        return python_code.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    with open('reference.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        answers = []\n",
    "\n",
    "        for row in reader:\n",
    "            id = row['id']\n",
    "            problem = row['problem']\n",
    "\n",
    "            print(f\"Solving problem {id}:\")\n",
    "            print(problem)\n",
    "\n",
    "            solution = solve_problem(id, problem)\n",
    "\n",
    "            print(f\"Your solution: {solution}\")\n",
    "            print()\n",
    "\n",
    "            answers.append({'id': id, 'solution': solution})\n",
    "\n",
    "        # Save answers to a CSV file\n",
    "        with open('answers.csv', 'w') as outfile:\n",
    "            fieldnames = ['id', 'solution']\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(answers)\n",
    "\n",
    "tokenizer = llm.get_tokenizer()\n",
    "ipython = get_ipython()\n",
    "PythonREPL = ipython.run_cell_magic(\"capture\", \"--no-stderr\", \"from IPython import InteractiveShell; PythonREPL = InteractiveShell.instance(); PythonREPL.run_cell('%load_ext autoreload'); PythonREPL.run_cell('%autoreload 2')\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (4.66.5)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: IPython in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (8.28.0)\n",
      "Requirement already satisfied: decorator in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from jedi>=0.16->IPython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from stack-data->IPython) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from stack-data->IPython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from stack-data->IPython) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mythii/miniconda3/envs/myenv/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->IPython) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install csv\n",
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
